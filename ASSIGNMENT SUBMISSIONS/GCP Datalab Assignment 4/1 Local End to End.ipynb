{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Development and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will cover the core parts of the machine learning workflow, running locally within the Google Cloud Datalab environment. Local development and validation, along with using a sample of the full dataset, is recommended as a starting point. This allows for a shorter development-validation iteration cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace Setup\n",
    "\n",
    "The first step is to setup the workspace that we will use within this notebook - the python libraries, and the local directory containing the data inputs and outputs produced over the course of the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import google.datalab.ml as ml\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plot\n",
    "import mltoolbox.regression.dnn as regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The local development workspace will be in `/content/datalab/workspace/census` by default.\n",
    "\n",
    "Note that the `/content/datalab` directory is physically located within the data disk mounted into the Datalab instance, but outside of the git repository containing notebooks, which makes it suitable for storing data files and generated files that are useful to keep around while you are working on a project, but do not belong in the source repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_path = '/content/datalab/workspace/census'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {workspace_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: If you have previously run this notebook, and want to start from scratch, then run the next cell to delete and create the workspace directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {workspace_path} && mkdir {workspace_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, we will copy the data into this workspace. Generally, in your own work, you will need to create a representative sample dataset to use for local development, while leaving the full dataset to use when running on the service. For purposes of the sample, which uses a relatively small dataset, we'll copy it down in entirety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "Updates are available for some Cloud SDK components.  To install them,\r\n",
      "please run:\r\n",
      "  $ gcloud components update\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil -q cp gs://cloud-datalab-samples/census/ss14psd.csv {workspace_path}/data/census.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8000\r\n",
      "-rw-r--r-- 1 root root 8189323 Sep 30 01:02 census.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {workspace_path}/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "Its a good idea to load data and inspect it to build an understanding of the structure, as well as preparation steps that will be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8626 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT</th>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>SPORDER</th>\n",
       "      <th>PUMA</th>\n",
       "      <th>ST</th>\n",
       "      <th>ADJINC</th>\n",
       "      <th>PWGTP</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>CITWP</th>\n",
       "      <th>...</th>\n",
       "      <th>pwgtp71</th>\n",
       "      <th>pwgtp72</th>\n",
       "      <th>pwgtp73</th>\n",
       "      <th>pwgtp74</th>\n",
       "      <th>pwgtp75</th>\n",
       "      <th>pwgtp76</th>\n",
       "      <th>pwgtp77</th>\n",
       "      <th>pwgtp78</th>\n",
       "      <th>pwgtp79</th>\n",
       "      <th>pwgtp80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>25</td>\n",
       "      <td>01</td>\n",
       "      <td>00400</td>\n",
       "      <td>46</td>\n",
       "      <td>1008425</td>\n",
       "      <td>00038</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>00011</td>\n",
       "      <td>00010</td>\n",
       "      <td>00008</td>\n",
       "      <td>00032</td>\n",
       "      <td>00040</td>\n",
       "      <td>00038</td>\n",
       "      <td>00033</td>\n",
       "      <td>00040</td>\n",
       "      <td>00068</td>\n",
       "      <td>00090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>467</td>\n",
       "      <td>01</td>\n",
       "      <td>00600</td>\n",
       "      <td>46</td>\n",
       "      <td>1008425</td>\n",
       "      <td>00120</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>00119</td>\n",
       "      <td>00039</td>\n",
       "      <td>00034</td>\n",
       "      <td>00119</td>\n",
       "      <td>00125</td>\n",
       "      <td>00104</td>\n",
       "      <td>00119</td>\n",
       "      <td>00102</td>\n",
       "      <td>00184</td>\n",
       "      <td>00038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>490</td>\n",
       "      <td>01</td>\n",
       "      <td>00500</td>\n",
       "      <td>46</td>\n",
       "      <td>1008425</td>\n",
       "      <td>00172</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>00049</td>\n",
       "      <td>00045</td>\n",
       "      <td>00148</td>\n",
       "      <td>00163</td>\n",
       "      <td>00313</td>\n",
       "      <td>00174</td>\n",
       "      <td>00153</td>\n",
       "      <td>00165</td>\n",
       "      <td>00158</td>\n",
       "      <td>00126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>490</td>\n",
       "      <td>02</td>\n",
       "      <td>00500</td>\n",
       "      <td>46</td>\n",
       "      <td>1008425</td>\n",
       "      <td>00113</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>00037</td>\n",
       "      <td>00032</td>\n",
       "      <td>00107</td>\n",
       "      <td>00125</td>\n",
       "      <td>00249</td>\n",
       "      <td>00107</td>\n",
       "      <td>00105</td>\n",
       "      <td>00094</td>\n",
       "      <td>00091</td>\n",
       "      <td>00079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>676</td>\n",
       "      <td>01</td>\n",
       "      <td>00300</td>\n",
       "      <td>46</td>\n",
       "      <td>1008425</td>\n",
       "      <td>00023</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>00022</td>\n",
       "      <td>00006</td>\n",
       "      <td>00035</td>\n",
       "      <td>00030</td>\n",
       "      <td>00028</td>\n",
       "      <td>00027</td>\n",
       "      <td>00020</td>\n",
       "      <td>00042</td>\n",
       "      <td>00019</td>\n",
       "      <td>00011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  RT SERIALNO SPORDER   PUMA  ST   ADJINC  PWGTP AGEP CIT CITWP   ...    \\\n",
       "0  P       25      01  00400  46  1008425  00038   85   1         ...     \n",
       "1  P      467      01  00600  46  1008425  00120   62   1         ...     \n",
       "2  P      490      01  00500  46  1008425  00172   64   1         ...     \n",
       "3  P      490      02  00500  46  1008425  00113   67   1         ...     \n",
       "4  P      676      01  00300  46  1008425  00023   89   1         ...     \n",
       "\n",
       "  pwgtp71 pwgtp72 pwgtp73 pwgtp74 pwgtp75 pwgtp76 pwgtp77 pwgtp78 pwgtp79  \\\n",
       "0   00011   00010   00008   00032   00040   00038   00033   00040   00068   \n",
       "1   00119   00039   00034   00119   00125   00104   00119   00102   00184   \n",
       "2   00049   00045   00148   00163   00313   00174   00153   00165   00158   \n",
       "3   00037   00032   00107   00125   00249   00107   00105   00094   00091   \n",
       "4   00022   00006   00035   00030   00028   00027   00020   00042   00019   \n",
       "\n",
       "  pwgtp80  \n",
       "0   00090  \n",
       "1   00038  \n",
       "2   00126  \n",
       "3   00079  \n",
       "4   00011  \n",
       "\n",
       "[5 rows x 284 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(os.path.join(workspace_path, 'data/census.csv'), dtype=str)\n",
    "print '%d rows' % len(df_data)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The census data contains a large number of columns. Only a few are needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Transformations\n",
    "\n",
    "The raw census data requires a number of transformations before it is usable for machine learning:\n",
    "\n",
    "1. Apply understanding of the domain and the problem to determine which data to include or join, as well as which data to filter out if it is adding noise. In the case of census, we'll pick just a few of the many columns present in the dataset.\n",
    "2. Handle missing values, or variations in formatting.\n",
    "3. Apply other transformations in support of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is packaged as a function that can be reused if you need to apply to future\n",
    "# datasets, esp. to prediction data, to ensure consistent transformations are applied.\n",
    "\n",
    "def transform_data(df):\n",
    "  interesting_columns = ['WAGP','SERIALNO','AGEP','COW','ESP','ESR','FOD1P','HINS4','INDP',\n",
    "                         'JWMNP', 'JWTR', 'MAR', 'POWPUMA', 'PUMA', 'RAC1P', 'SCHL',\n",
    "                         'SCIENGRLP', 'SEX', 'WKW']\n",
    "  df = df[interesting_columns]\n",
    "  \n",
    "  # Replace whitespace with NaN, and NaNs with empty string\n",
    "  df = df.replace('\\s+', np.nan, regex=True).fillna('')\n",
    "\n",
    "  # Filter out the rows without an income, i.e. there is no target value to learn from\n",
    "  df = df[df.WAGP != '']\n",
    "  \n",
    "  # Convert the wage value into units of 1000. So someone making an income from wages\n",
    "  # of $23200 will have it encoded as 23.2\n",
    "  df['WAGP'] = df.WAGP.astype(np.int64) / 1000.0\n",
    "\n",
    "  # Filter out rows with income values we don't care about, i.e. outliers\n",
    "  # Filter out rows with less than 10K and more than 150K\n",
    "  df = df[(df.WAGP >= 10.0) & (df.WAGP < 150.0)]\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3390 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAGP</th>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>ESP</th>\n",
       "      <th>ESR</th>\n",
       "      <th>FOD1P</th>\n",
       "      <th>HINS4</th>\n",
       "      <th>INDP</th>\n",
       "      <th>JWMNP</th>\n",
       "      <th>JWTR</th>\n",
       "      <th>MAR</th>\n",
       "      <th>POWPUMA</th>\n",
       "      <th>PUMA</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>SCIENGRLP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>WKW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.0</td>\n",
       "      <td>467</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2102</td>\n",
       "      <td>2</td>\n",
       "      <td>6990</td>\n",
       "      <td>015</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>00590</td>\n",
       "      <td>00600</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>490</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>8090</td>\n",
       "      <td>015</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>00590</td>\n",
       "      <td>00500</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1225</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>5301</td>\n",
       "      <td>2</td>\n",
       "      <td>9680</td>\n",
       "      <td>015</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>00100</td>\n",
       "      <td>00100</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1225</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>8680</td>\n",
       "      <td>020</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>00100</td>\n",
       "      <td>00100</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1438</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>6170</td>\n",
       "      <td>030</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>00100</td>\n",
       "      <td>00100</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    WAGP SERIALNO AGEP COW ESP ESR FOD1P HINS4  INDP JWMNP JWTR MAR POWPUMA  \\\n",
       "1   70.0      467   62   1       1  2102     2  6990   015   01   3   00590   \n",
       "2   19.0      490   64   2       1           2  8090   015   01   1   00590   \n",
       "6   70.0     1225   32   5       4  5301     2  9680   015   01   1   00100   \n",
       "7   18.0     1225   30   1       1           2  8680   020   01   1   00100   \n",
       "11  45.0     1438   55   1       1           2  6170   030   01   1   00100   \n",
       "\n",
       "     PUMA RAC1P SCHL SCIENGRLP SEX WKW  \n",
       "1   00600     1   21         2   1   1  \n",
       "2   00500     1   18             2   1  \n",
       "6   00100     1   21         2   1   1  \n",
       "7   00100     1   16             2   1  \n",
       "11  00100     1   16             1   1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = transform_data(df_data)\n",
    "print '%d rows' % len(df_data)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataSets\n",
    "\n",
    "Once the data is ready, the next step is to split data into training and evaluation datasets. In this sample, rows are split randomly in an 80/20 manner. Additionally, the schema is also saved for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_schema(df):\n",
    "  fields = []\n",
    "  for name, dtype in zip(df.columns, df.dtypes):\n",
    "    if dtype in (np.str, np.object):\n",
    "      # Categorical columns should have type 'STRING'\n",
    "      fields.append({'name': name, 'type': 'STRING'})\n",
    "    elif dtype in (np.int32, np.int64, np.float32, np.float64):\n",
    "      # Numerical columns have type 'FLOAT'\n",
    "      fields.append({'name': name, 'type': 'FLOAT'})\n",
    "    else:\n",
    "      raise ValueError('Unsupported column type \"%s\" in column \"%s\"' % (str(dtype), name))\n",
    "  return fields\n",
    "\n",
    "def create_datasets(df):\n",
    "  # Numbers in the range of [0, 1)\n",
    "  random_values = np.random.rand(len(df))\n",
    "\n",
    "  # Split data into %80, 20% partitions\n",
    "  df_train = df[random_values < 0.8]\n",
    "  df_eval = df[random_values >= 0.8]\n",
    "\n",
    "  return df_train, df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_eval = create_datasets(df_data)\n",
    "schema = create_schema(df_data)\n",
    "\n",
    "training_data_path = os.path.join(workspace_path, 'data/train.csv')\n",
    "eval_data_path = os.path.join(workspace_path, 'data/eval.csv')\n",
    "schema_path = os.path.join(workspace_path, 'data/schema.json')\n",
    "\n",
    "df_train.to_csv(training_data_path, header=False, index=False)\n",
    "df_eval.to_csv(eval_data_path, header=False, index=False)\n",
    "\n",
    "with open(schema_path, 'w') as f:\n",
    "  f.write(json.dumps(schema, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8204\r\n",
      "-rw-r--r-- 1 root root 8189323 Sep 30 01:02 census.csv\r\n",
      "-rw-r--r-- 1 root root   40743 Sep 30 01:03 eval.csv\r\n",
      "-rw-r--r-- 1 root root     998 Sep 30 01:03 schema.json\r\n",
      "-rw-r--r-- 1 root root  162812 Sep 30 01:03 train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {workspace_path}/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create DataSet objects which are reference to one or more files identified by a path (or path pattern) along with associated schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ml.CsvDataSet(file_pattern=training_data_path, schema_file=schema_path)\n",
    "eval_data = ml.CsvDataSet(file_pattern=eval_data_path, schema_file=schema_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Data\n",
    "\n",
    "When building a model, a number of pieces of information about the training data are required - for example, the list of entries or vocabulary of a categorical/discrete column, or aggregate statistics like min and max for numerical columns. These require a full pass over the training data, and is usually done once, and needs to be repeated once if you change the schema in a future iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze: completed\n"
     ]
    }
   ],
   "source": [
    "analysis_path = os.path.join(workspace_path, 'analysis')\n",
    "\n",
    "regression.analyze(dataset=train_data, output_dir=analysis_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of analysis is a stats file that contains analysis from the numerical columns, and a vocab file from each categorical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema.json\tvocab_ESR.csv\t vocab_JWTR.csv     vocab_SCHL.csv\r\n",
      "stats.json\tvocab_FOD1P.csv  vocab_MAR.csv\t    vocab_SCIENGRLP.csv\r\n",
      "vocab_AGEP.csv\tvocab_HINS4.csv  vocab_POWPUMA.csv  vocab_SERIALNO.csv\r\n",
      "vocab_COW.csv\tvocab_INDP.csv\t vocab_PUMA.csv     vocab_SEX.csv\r\n",
      "vocab_ESP.csv\tvocab_JWMNP.csv  vocab_RAC1P.csv    vocab_WKW.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls {analysis_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "All the data is in place to start training. A model learns to predict the target value (the income, 'WAGP'), based on the different pieces of input data (the various columns or features). The target and inputs are defined as features derived from the input data by applying a set of transforms to the columns.\n",
    "\n",
    "Additionally there is a special key column - this is any column in the data that can be used to uniquely identify instances. The value of this column is ignored during training, but this value is quite useful when using the resulting model during prediction as discussed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "  \"WAGP\": {\"transform\": \"target\"},\n",
    "  \"SERIALNO\": {\"transform\": \"key\"},\n",
    "  \"AGEP\": {\"transform\": \"embedding\", \"embedding_dim\": 2},  # Age\n",
    "  \"COW\": {\"transform\": \"one_hot\"},                         # Class of worker\n",
    "  \"ESP\": {\"transform\": \"embedding\", \"embedding_dim\": 2},   # Employment status of parents\n",
    "  \"ESR\": {\"transform\": \"one_hot\"},                         # Employment status\n",
    "  \"FOD1P\": {\"transform\": \"embedding\", \"embedding_dim\": 3}, # Field of degree\n",
    "  \"HINS4\": {\"transform\": \"one_hot\"},                       # Medicaid\n",
    "  \"INDP\": {\"transform\": \"embedding\", \"embedding_dim\": 5},  # Industry\n",
    "  \"JWMNP\": {\"transform\": \"embedding\", \"embedding_dim\": 2}, # Travel time to work\n",
    "  \"JWTR\": {\"transform\": \"one_hot\"},                        # Transportation\n",
    "  \"MAR\": {\"transform\": \"one_hot\"},                         # Marital status\n",
    "  \"POWPUMA\": {\"transform\": \"one_hot\"},                     # Place of work\n",
    "  \"PUMA\": {\"transform\": \"one_hot\"},                        # Area code\n",
    "  \"RAC1P\": {\"transform\": \"one_hot\"},                       # Race\n",
    "  \"SCHL\": {\"transform\": \"one_hot\"},                        # School\n",
    "  \"SCIENGRLP\": {\"transform\": \"one_hot\"},                   # Science\n",
    "  \"SEX\": {\"transform\": \"one_hot\"},\n",
    "  \"WKW\": {\"transform\": \"one_hot\"}                          # Weeks worked\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2218.3813, step = 1\n",
      "INFO:tensorflow:Saving dict for global step 1: global_step = 1, loss = 1974.4193\n",
      "INFO:tensorflow:global_step/sec: 38.2256\n",
      "INFO:tensorflow:loss = 334.9252, step = 101 (2.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.352\n",
      "INFO:tensorflow:loss = 262.20618, step = 201 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.93\n",
      "INFO:tensorflow:loss = 253.09422, step = 301 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.098\n",
      "INFO:tensorflow:loss = 145.83206, step = 401 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.446\n",
      "INFO:tensorflow:loss = 228.5083, step = 501 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.283\n",
      "INFO:tensorflow:loss = 190.3227, step = 601 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.639\n",
      "INFO:tensorflow:loss = 210.18117, step = 701 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.864\n",
      "INFO:tensorflow:loss = 230.09373, step = 801 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.748\n",
      "INFO:tensorflow:loss = 335.26233, step = 901 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.484\n",
      "INFO:tensorflow:loss = 201.26369, step = 1001 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.241\n",
      "INFO:tensorflow:loss = 213.94366, step = 1101 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.613\n",
      "INFO:tensorflow:loss = 189.62383, step = 1201 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.527\n",
      "INFO:tensorflow:loss = 198.97281, step = 1301 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.688\n",
      "INFO:tensorflow:loss = 159.50052, step = 1401 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.278\n",
      "INFO:tensorflow:loss = 136.889, step = 1501 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.016\n",
      "INFO:tensorflow:loss = 267.99396, step = 1601 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.513\n",
      "INFO:tensorflow:loss = 182.52156, step = 1701 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.371\n",
      "INFO:tensorflow:loss = 163.608, step = 1801 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.102\n",
      "INFO:tensorflow:loss = 148.86296, step = 1901 (0.395 sec)\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 493.6558\n",
      "Training: completed\n"
     ]
    }
   ],
   "source": [
    "training_path = os.path.join(workspace_path, 'training')\n",
    "regression.train(train_dataset=train_data, eval_dataset=eval_data,\n",
    "                 output_dir=training_path,\n",
    "                 analysis_dir=analysis_path,\n",
    "                 features=features,\n",
    "                 max_steps=2000,\n",
    "                 layer_sizes=[5, 5, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard\n",
    "\n",
    "A training job produces various summary events containing values of metrics (eg. throughput and loss) over the course of its execution. These events can be observed in TensorBoard while the job executes or after it is executed.\n",
    "\n",
    "In this sample, training was short, and has completed. In the general case, especially for longer cloud training jobs, it is more interesting to launch TensorBoard while the training job continues to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 4501. Click <a href=\"/_proxy/48501/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard_pid = ml.TensorBoard.start(training_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.TensorBoard.stop(tensorboard_pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Trained Model\n",
    "\n",
    "It is interesting to get a sense of all the outputs produced during training, in addition to the summary event files, visualized in the previous step. In particular, note that the model is produced in a `model` subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/datalab/workspace/census/training/model:\r\n",
      "assets.extra  saved_model.pb  variables\r\n",
      "\r\n",
      "/content/datalab/workspace/census/training/model/assets.extra:\r\n",
      "features.json  schema.json\r\n",
      "\r\n",
      "/content/datalab/workspace/census/training/model/variables:\r\n",
      "variables.data-00000-of-00001  variables.index\r\n"
     ]
    }
   ],
   "source": [
    "!ls -R {training_path}/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Once a model has been trained, it is necessary to evaluate it and understand how well it is performing. In order to evaluate a model, batch prediction jobs can be run against the one or more evaluation datasets that you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /content/datalab/workspace/census/training/evaluation_model/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /content/datalab/workspace/census/training/evaluation_model/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch predict: completed\n"
     ]
    }
   ],
   "source": [
    "evaluation_path = os.path.join(workspace_path, 'evaluation')\n",
    "\n",
    "# Note the use of evaluation mode (as opposed to prediction mode). This is used to indicate the data being\n",
    "# predicted on contains a target value column (prediction data is missing that column).\n",
    "regression.batch_predict(training_dir=training_path,\n",
    "                         prediction_input_file=eval_data_path,\n",
    "                         output_dir=evaluation_path,\n",
    "                         output_format='json',\n",
    "                         mode='evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 48\r\n",
      "-rw-r--r-- 1 root root     0 Sep 30 01:04 errors-00000-of-00001.txt\r\n",
      "-rw-r--r-- 1 root root 48395 Sep 30 01:04 predictions-00000-of-00001.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {evaluation_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>predicted</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2892</td>\n",
       "      <td>9.434464</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8625</td>\n",
       "      <td>10.008234</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11735</td>\n",
       "      <td>50.316925</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14981</td>\n",
       "      <td>2.730933</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17989</td>\n",
       "      <td>88.905617</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SERIALNO  predicted  target\n",
       "0      2892   9.434464    16.0\n",
       "1      8625  10.008234    22.4\n",
       "2     11735  50.316925    20.0\n",
       "3     14981   2.730933    60.0\n",
       "4     17989  88.905617   120.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = pd.read_json(os.path.join(evaluation_path, 'predictions-00000-of-00001.json'), lines=True)\n",
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 22.214\n"
     ]
    }
   ],
   "source": [
    "mse = metrics.mean_squared_error(df_eval['target'], df_eval['predicted'])\n",
    "rmse = math.sqrt(mse)\n",
    "print 'Root Mean Squared Error: %.3f' % rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/matplotlib/font_manager.py:1320: UserWarning: findfont: Font family [u'sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f799080d710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_eval['error'] = df_eval['predicted'] - df_eval['target']\n",
    "_ = plot.hist(df_eval['error'], bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The root mean squared error and distribution of errors indicates how the model is performing at an aggregate level as well as indicative of the span of error values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Now that a model has been trained, and saved on-disk, it can be reloaded using TensorFlow, and be used to produce predictions, i.e. produce the income value given a set of new instances, or features that were not previously present in the training data. This mechanism can also help validate the model - it can be used to produce predictions for one or more evaluation datasets.\n",
    "\n",
    "Note that prediction data must be of the same type (input format, and order of columns) as the data that was used for training. The only difference is the first column, the target income value, is absent.\n",
    "\n",
    "Since the model is a regression model, a single value is the output of the prediction.\n",
    "\n",
    "Also note that second column in our schema was specified as a key column. This value of the key will accompany the output values, so they can be joined with the input instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /content/datalab/workspace/census/data/prediction.csv\n"
     ]
    }
   ],
   "source": [
    "%file {workspace_path}/data/prediction.csv\n",
    "SERIALNO,AGEP,COW,ESP,ESR,FOD1P,HINS4,INDP,JWMNP,JWTR,MAR,POWPUMA,PUMA,RAC1P,SCHL,SCIENGRLP,SEX,WKW\n",
    "490,64,2,0,1,0,2,8090,015,01,1,00590,00500,1,18,0,2,1\n",
    "1225,32,5,0,4,5301,2,9680,015,01,1,00100,00100,1,21,2,1,1\n",
    "1226,30,1,0,1,0,2,8680,020,01,1,00100,00100,1,16,0,2,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>ESP</th>\n",
       "      <th>ESR</th>\n",
       "      <th>FOD1P</th>\n",
       "      <th>HINS4</th>\n",
       "      <th>INDP</th>\n",
       "      <th>JWMNP</th>\n",
       "      <th>JWTR</th>\n",
       "      <th>MAR</th>\n",
       "      <th>POWPUMA</th>\n",
       "      <th>PUMA</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>SCIENGRLP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>WKW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>490</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8090</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>590</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1225</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5301</td>\n",
       "      <td>2</td>\n",
       "      <td>9680</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1226</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8680</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SERIALNO  AGEP  COW  ESP  ESR  FOD1P  HINS4  INDP  JWMNP  JWTR  MAR  \\\n",
       "0       490    64    2    0    1      0      2  8090     15     1    1   \n",
       "1      1225    32    5    0    4   5301      2  9680     15     1    1   \n",
       "2      1226    30    1    0    1      0      2  8680     20     1    1   \n",
       "\n",
       "   POWPUMA  PUMA  RAC1P  SCHL  SCIENGRLP  SEX  WKW  \n",
       "0      590   500      1    18          0    2    1  \n",
       "1      100   100      1    21          2    1    1  \n",
       "2      100   100      1    16          0    2    1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_instances = pd.read_csv(os.path.join(workspace_path, 'data/prediction.csv'))\n",
    "df_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /content/datalab/workspace/census/training/model/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /content/datalab/workspace/census/training/model/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /content/datalab/workspace/census/training/model/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /content/datalab/workspace/census/training/model/variables/variables\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>490</td>\n",
       "      <td>27.966228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1225</td>\n",
       "      <td>53.706852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1226</td>\n",
       "      <td>12.061103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SERIALNO  predicted\n",
       "0       490  27.966228\n",
       "1      1225  53.706852\n",
       "2      1226  12.061103"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions = regression.predict(training_dir=training_path, data=df_instances)\n",
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>ESP</th>\n",
       "      <th>ESR</th>\n",
       "      <th>FOD1P</th>\n",
       "      <th>HINS4</th>\n",
       "      <th>INDP</th>\n",
       "      <th>JWMNP</th>\n",
       "      <th>JWTR</th>\n",
       "      <th>MAR</th>\n",
       "      <th>POWPUMA</th>\n",
       "      <th>PUMA</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>SCIENGRLP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>WKW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SERIALNO</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>27.966228</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8090</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>590</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>53.706852</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5301</td>\n",
       "      <td>2</td>\n",
       "      <td>9680</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>12.061103</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8680</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted  AGEP  COW  ESP  ESR  FOD1P  HINS4  INDP  JWMNP  JWTR  \\\n",
       "SERIALNO                                                                    \n",
       "490       27.966228    64    2    0    1      0      2  8090     15     1   \n",
       "1225      53.706852    32    5    0    4   5301      2  9680     15     1   \n",
       "1226      12.061103    30    1    0    1      0      2  8680     20     1   \n",
       "\n",
       "          MAR  POWPUMA  PUMA  RAC1P  SCHL  SCIENGRLP  SEX  WKW  \n",
       "SERIALNO                                                        \n",
       "490         1      590   500      1    18          0    2    1  \n",
       "1225        1      100   100      1    21          2    1    1  \n",
       "1226        1      100   100      1    16          0    2    1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index the instances DataFrame using the SERIALNO column, and join the predictions\n",
    "# DataFrame using the same column.\n",
    "df_instances.set_index(keys=['SERIALNO'], inplace=True)\n",
    "df_predictions.set_index(keys=['SERIALNO'], inplace=True)\n",
    "\n",
    "df_data = df_predictions.join(other=df_instances)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "This notebook covered key stages of the workflow locally - data preparation, data analysis, training, and prediction. Once there is a working model, the next step is to use the full dataset, and scale to much larger data volumes by performing these steps in cloud using BigQuery, Machine Learning Engine, and Dataflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
